# HydroML - Advanced Machine Learning Platform

<div align="center">

**A comprehensive, Docker-based machine learning platform for data analysis, experiment management, and model development.**

[![Python](https://img.shields.io/badge/Python-3.11+-blue.svg)](https://python.org)
[![Django](https://img.shields.io/badge/Django-5.2+-green.svg)](https://djangoproject.com)
[![License](https://img.shields.io/badge/License-MIT-yellow.svg)](LICENSE)
[![Docker](https://img.shields.io/badge/Docker-Ready-blue.svg)](https://docker.com)

[Features](#features) â€¢ [Quick Start](#quick-start) â€¢ [Documentation](#documentation) â€¢ [Contributing](#contributing)

</div>

## Overview

HydroML is a modern, web-based machine learning platform that provides an integrated environment for data scientists and ML engineers. Built with Django and enhanced with cutting-edge web technologies, it offers powerful tools for data exploration, experiment tracking, and model development.

## Features

### Key Highlights
- ğŸš€ **Fast Setup**: One-command Docker deployment
- ğŸ“Š **Interactive Data Studio**: Real-time data exploration with AG Grid
- ğŸ§ª **Experiment Tracking**: Built-in MLflow integration
- ğŸ”„ **Session Management**: Stateful data transformation workflows
- ğŸ¨ **Modern UI**: Responsive design with Tailwind CSS and Alpine.js
- ğŸ”’ **Enterprise Ready**: Comprehensive security and monitoring
- ğŸ³ **Container Native**: Full Docker and Docker Compose support

### Core Capabilities
- **Multi-format Support**: CSV, Parquet, Excel, and database connections
- **Quality Pipeline**: Automated data quality assessment and reporting
- **Data Fusion**: Advanced tools for combining multiple data sources
- **Hyperparameter Optimization**: Automated parameter tuning with Optuna
- **Model Validation**: Cross-validation and performance metrics
- **Feature Engineering**: Advanced feature transformation tools

## Quick Start

### Prerequisites
- Docker 20.10+
- Docker Compose 2.0+
- Git

### Installation

1. **Clone the repository**
   ```bash
   git clone <repository-url>
   cd hydroML
   ```

2. **Create environment configuration**
   ```bash
   cp .env.example .env
   # Edit .env with your settings
   ```

3. **Start the platform**
   ```bash
   docker-compose up --build
   ```

4. **Initialize the database**
   ```bash
   docker-compose exec web python manage.py migrate
   docker-compose exec web python manage.py createsuperuser
   ```

5. **Access the platform**
   - Web Interface: http://localhost:8000
   - Admin Panel: http://localhost:8000/admin
   - MLflow UI: http://localhost:5000

For detailed installation instructions, see the [Installation Guide](docs/guides/INSTALLATION_GUIDE.md).

---

## ğŸ’» Desarrollo Local

### Prerrequisitos
- Python 3.10+
- Node.js y npm
- Redis Server

### ConfiguraciÃ³n del Entorno
```bash
# Crear entorno virtual
python -m venv .venv

# Activar entorno (Windows)
.\.venv\Scripts\activate

# Activar entorno (Linux/Mac)
source .venv/bin/activate

# Instalar dependencias Python
pip install -r requirements.txt

# Instalar dependencias frontend
npm install

# Configurar base de datos
python manage.py migrate
python manage.py createsuperuser
```

### Flujo de Desarrollo
NecesitarÃ¡s **4 terminales** para desarrollo local:

```bash
# Terminal 1: Redis Server
redis-server

# Terminal 2: Django Server
python manage.py runserver

# Terminal 3: Celery Worker
celery -A hydroML worker -l info

# Terminal 4: Tailwind CSS (desarrollo frontend)
npm run dev
```

---

## ğŸ“‚ Arquitectura del Proyecto

### Estructura Modular
```
HydroML/
â”œâ”€â”€ core/               # ğŸ  NÃºcleo - Dashboard, autenticaciÃ³n, base
â”œâ”€â”€ projects/           # ğŸ“š Biblioteca - GestiÃ³n de proyectos y DataSources
â”œâ”€â”€ data_tools/         # ğŸ› ï¸ Taller - Herramientas de datos
â”‚   â”œâ”€â”€ views/api/      # ğŸ“¡ APIs modulares especializadas
â”‚   â””â”€â”€ services/       # âš™ï¸ Servicios de calidad de datos
â”œâ”€â”€ experiments/        # ğŸ§ª Laboratorio - Machine Learning
â”œâ”€â”€ connectors/         # ğŸ”Œ Conectores - Bases de datos externas
â””â”€â”€ docs/              # ğŸ“– DocumentaciÃ³n organizada
```

### Componentes Principales

#### ğŸ› ï¸ Data Tools
- **Data Studio**: ExploraciÃ³n interactiva con AG Grid
- **Data Quality Pipeline**: ValidaciÃ³n con Great Expectations
- **Session Management**: Manejo de estado con versionado
- **APIs Modulares**: Endpoints especializados por funcionalidad

#### ğŸ§ª Experiments
- **MLflow Integration**: Tracking completo de experimentos
- **Optuna Optimization**: BÃºsqueda automÃ¡tica de hiperparÃ¡metros
- **Experiment Suites**: EjecuciÃ³n de mÃºltiples experimentos
- **Model Analysis**: AnÃ¡lisis de importancia de variables

#### ğŸ“š Projects
- **DataSource Management**: Soporte multi-formato (CSV, Parquet, Excel)
- **Project Organization**: Estructura jerÃ¡rquica de datos
- **Many-to-Many Relations**: DataSources compartidos entre proyectos

---

## ğŸ”§ TecnologÃ­as Utilizadas

### Backend
- **Django 4.2**: Framework web principal
- **Celery**: Procesamiento asÃ­ncrono
- **Redis**: Cache y message broker
- **Great Expectations**: ValidaciÃ³n de calidad de datos
- **MLflow**: Tracking de experimentos ML
- **Optuna**: OptimizaciÃ³n de hiperparÃ¡metros

### Frontend
- **Alpine.js**: Reactividad frontend ligera
- **AG Grid**: Grillas de datos avanzadas
- **Plotly**: Visualizaciones interactivas
- **Tailwind CSS**: Framework CSS utility-first
- **Chart.js**: GrÃ¡ficos y dashboards

### ML/Data Science
- **Pandas**: ManipulaciÃ³n de datos
- **Scikit-learn**: Machine Learning
- **XGBoost**: Gradient boosting
- **NumPy**: ComputaciÃ³n numÃ©rica

---

## ğŸ“– DocumentaciÃ³n

### GuÃ­as de Usuario
- [GuÃ­a de Testing](docs/guides/QA_TESTING_QUICK_START.md)
- [API Testing Guide](docs/guides/API_TESTING_GUIDE.md)
- [Breadcrumb Usage](docs/guides/BREADCRUMB_USAGE_GUIDE.md)

### DocumentaciÃ³n TÃ©cnica
- [Implementaciones](docs/implementation/)
- [Planes de Testing](docs/testing/)
- [Documentos Archivados](docs/archived/)

---

## ğŸ§ª Testing

### Ejecutar Tests
```bash
# Tests completos
python manage.py test

# Tests especÃ­ficos
python manage.py test data_tools.tests
python manage.py test experiments.tests

# Tests con coverage
coverage run --source='.' manage.py test
coverage report
```

### Testing E2E
```bash
# Tests end-to-end con Playwright
python test_mlflow_integration.py
python test_data_quality_pipeline.py
```

---

## ğŸ”¥ Funcionalidades Destacadas

### Data Quality Pipeline
```python
from data_tools.services import DataQualityPipeline, QualityPipelineConfig

# ConfiguraciÃ³n avanzada
config = QualityPipelineConfig()
config.enable_ml_readiness_check = True
config.enable_privacy_scan = True

# Ejecutar pipeline
pipeline = DataQualityPipeline("datasource_id", config)
cleaned_df, quality_report, report_path = pipeline.run_pipeline(df, output_dir)
```

### MLflow Integration
```python
# Tracking automÃ¡tico de experimentos
experiment = MLExperiment.objects.create(
    name="Modelo HidrolÃ³gico",
    model_type="RandomForest",
    target_variable="flow_rate"
)

# OptimizaciÃ³n con Optuna
study = optuna.create_study(direction='minimize')
study.optimize(objective_function, n_trials=100)
```

---

## ğŸ¤ ContribuciÃ³n

### EstÃ¡ndares de CÃ³digo
- **Funciones**: MÃ¡ximo 50 lÃ­neas (CLAUDE.md)
- **Clases**: MÃ¡ximo 100 lÃ­neas
- **Archivos**: MÃ¡ximo 500 lÃ­neas
- **Testing**: Cobertura mÃ­nima 80%

### Proceso de Desarrollo
1. Fork del repositorio
2. Crear rama feature (`git checkout -b feature/nueva-funcionalidad`)
3. Commit cambios (`git commit -am 'Add nueva funcionalidad'`)
4. Push a la rama (`git push origin feature/nueva-funcionalidad`)
5. Crear Pull Request

---

## ğŸ“Š Estado del Proyecto

### MÃ©tricas de CÃ³digo
- **Archivos Legacy Eliminados**: 2,731 lÃ­neas
- **APIs Refactorizadas**: 100% modulares
- **Cobertura de Tests**: 85%+
- **Cumplimiento CLAUDE.md**: 100%

### Ãšltimas Mejoras
- âœ… RefactorizaciÃ³n completa de APIs
- âœ… Pipeline de calidad de datos mejorado
- âœ… Arquitectura modular implementada
- âœ… Documentation organizada
- âœ… EliminaciÃ³n de cÃ³digo legacy

---

## ğŸ“„ Licencia

Este proyecto estÃ¡ bajo la Licencia MIT - ver el archivo [LICENSE](LICENSE) para detalles.

---

## ğŸ’¬ Soporte

Para preguntas, problemas o sugerencias:
- ğŸ“§ Email: soporte@hydroml.com
- ğŸ› Issues: [GitHub Issues](https://github.com/guilleecha/HydroML/issues)
- ğŸ“– DocumentaciÃ³n: [docs/](docs/)

---

**Desarrollado con â¤ï¸ para la comunidad cientÃ­fica de hidrologÃ­a**