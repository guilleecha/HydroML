"""
Data Studio Transformation API Views for stateful data transformations.
These endpoints apply transformations to cached DataFrames in the session.
"""

import json
import logging
import pandas as pd
import numpy as np
from typing import Dict, Any, Optional

from django.http import JsonResponse
from django.views.decorators.http import require_http_methods
from django.views.decorators.csrf import csrf_exempt
from django.contrib.auth.decorators import login_required
from django.shortcuts import get_object_or_404

from projects.models import DataSource
from data_tools.services.session_manager import get_session_manager

# Feature-engine imports for transformations
from feature_engine.imputation import MeanMedianImputer, CategoricalImputer
from feature_engine.encoding import OneHotEncoder, OrdinalEncoder
from feature_engine.discretisation import EqualFrequencyDiscretiser, EqualWidthDiscretiser
from feature_engine.outliers import Winsorizer
from feature_engine.transformation import LogTransformer, ReciprocalTransformer
# from feature_engine.wrappers import SklearnTransformerWrapper  # Temporarily disabled
from sklearn.preprocessing import StandardScaler, MinMaxScaler

logger = logging.getLogger(__name__)


@csrf_exempt
@login_required
@require_http_methods(["POST"])
def apply_missing_data_imputation(request, datasource_id):
    """
    Apply missing data imputation to the current session DataFrame.
    """
    try:
        datasource = get_object_or_404(DataSource, id=datasource_id, project__owner=request.user)
        session_manager = get_session_manager(request.user.id, datasource_id)
        
        # Get current DataFrame
        current_df = session_manager.get_current_dataframe()
        if current_df is None:
            return JsonResponse({
                'success': False,
                'error': 'No active session found. Please initialize session first.'
            }, status=400)
        
        # Parse request data
        data = json.loads(request.body)
        columns = data.get('columns', [])
        method = data.get('method', 'mean')  # mean, median, mode, constant
        constant_value = data.get('constant_value', None)
        
        if not columns:
            return JsonResponse({
                'success': False,
                'error': 'No columns specified for imputation'
            }, status=400)
        
        # Apply transformation
        df_copy = current_df.copy()
        
        # Separate numeric and categorical columns
        numeric_cols = [col for col in columns if col in df_copy.select_dtypes(include=[np.number]).columns]
        categorical_cols = [col for col in columns if col in df_copy.select_dtypes(include=['object', 'category']).columns]
        
        if numeric_cols:
            if method in ['mean', 'median']:
                imputer = MeanMedianImputer(imputation_method=method, variables=numeric_cols)
                df_copy = imputer.fit_transform(df_copy)
            elif method == 'constant' and constant_value is not None:
                df_copy[numeric_cols] = df_copy[numeric_cols].fillna(float(constant_value))
        
        if categorical_cols:
            if method == 'mode':
                cat_imputer = CategoricalImputer(imputation_method='frequent', variables=categorical_cols)
                df_copy = cat_imputer.fit_transform(df_copy)
            elif method == 'constant' and constant_value is not None:
                df_copy[categorical_cols] = df_copy[categorical_cols].fillna(str(constant_value))
        
        # Apply transformation to session
        operation_description = f"Imputed missing values in {len(columns)} columns using {method} method"
        success = session_manager.apply_transformation(df_copy, operation_description)
        
        if not success:
            return JsonResponse({
                'success': False,
                'error': 'Failed to apply transformation'
            }, status=500)
        
        # Return updated data preview and session info
        session_info = session_manager.get_session_info()
        data_preview = df_copy.head(100).to_dict('records')
        
        return JsonResponse({
            'success': True,
            'message': operation_description,
            'session_info': session_info,
            'data_preview': data_preview,
            'transformation_applied': {
                'type': 'missing_data_imputation',
                'columns': columns,
                'method': method,
                'rows_affected': len(df_copy)
            }
        })
        
    except Exception as e:
        logger.error(f"Failed to apply missing data imputation: {e}")
        return JsonResponse({
            'success': False,
            'error': str(e)
        }, status=500)


@csrf_exempt
@login_required
@require_http_methods(["POST"])
def apply_feature_encoding(request, datasource_id):
    """
    Apply feature encoding (one-hot, ordinal) to categorical columns.
    """
    try:
        datasource = get_object_or_404(DataSource, id=datasource_id, project__owner=request.user)
        session_manager = get_session_manager(request.user.id, datasource_id)
        
        current_df = session_manager.get_current_dataframe()
        if current_df is None:
            return JsonResponse({
                'success': False,
                'error': 'No active session found. Please initialize session first.'
            }, status=400)
        
        # Parse request data
        data = json.loads(request.body)
        columns = data.get('columns', [])
        encoding_type = data.get('encoding_type', 'onehot')  # onehot, ordinal
        
        if not columns:
            return JsonResponse({
                'success': False,
                'error': 'No columns specified for encoding'
            }, status=400)
        
        # Validate columns are categorical
        categorical_cols = current_df.select_dtypes(include=['object', 'category']).columns
        invalid_cols = [col for col in columns if col not in categorical_cols]
        
        if invalid_cols:
            return JsonResponse({
                'success': False,
                'error': f'Columns {invalid_cols} are not categorical'
            }, status=400)
        
        # Apply transformation
        df_copy = current_df.copy()
        
        if encoding_type == 'onehot':
            encoder = OneHotEncoder(variables=columns)
            df_copy = encoder.fit_transform(df_copy)
        elif encoding_type == 'ordinal':
            encoder = OrdinalEncoder(variables=columns)
            df_copy = encoder.fit_transform(df_copy)
        
        # Apply transformation to session
        operation_description = f"Applied {encoding_type} encoding to {len(columns)} categorical columns"
        success = session_manager.apply_transformation(df_copy, operation_description)
        
        if not success:
            return JsonResponse({
                'success': False,
                'error': 'Failed to apply transformation'
            }, status=500)
        
        # Return updated data preview and session info
        session_info = session_manager.get_session_info()
        data_preview = df_copy.head(100).to_dict('records')
        
        return JsonResponse({
            'success': True,
            'message': operation_description,
            'session_info': session_info,
            'data_preview': data_preview,
            'transformation_applied': {
                'type': 'feature_encoding',
                'columns': columns,
                'encoding_type': encoding_type,
                'new_columns_count': len(df_copy.columns) - len(current_df.columns)
            }
        })
        
    except Exception as e:
        logger.error(f"Failed to apply feature encoding: {e}")
        return JsonResponse({
            'success': False,
            'error': str(e)
        }, status=500)


@csrf_exempt
@login_required
@require_http_methods(["POST"])
def apply_feature_scaling(request, datasource_id):
    """
    Apply feature scaling (standardization, normalization) to numeric columns.
    """
    try:
        datasource = get_object_or_404(DataSource, id=datasource_id, project__owner=request.user)
        session_manager = get_session_manager(request.user.id, datasource_id)
        
        current_df = session_manager.get_current_dataframe()
        if current_df is None:
            return JsonResponse({
                'success': False,
                'error': 'No active session found. Please initialize session first.'
            }, status=400)
        
        # Parse request data
        data = json.loads(request.body)
        columns = data.get('columns', [])
        scaling_type = data.get('scaling_type', 'standard')  # standard, minmax
        
        if not columns:
            return JsonResponse({
                'success': False,
                'error': 'No columns specified for scaling'
            }, status=400)
        
        # Validate columns are numeric
        numeric_cols = current_df.select_dtypes(include=[np.number]).columns
        invalid_cols = [col for col in columns if col not in numeric_cols]
        
        if invalid_cols:
            return JsonResponse({
                'success': False,
                'error': f'Columns {invalid_cols} are not numeric'
            }, status=400)
        
        # Apply transformation
        df_copy = current_df.copy()
        
        if scaling_type == 'standard':
            scaler = StandardScaler(variables=columns)
            df_copy = scaler.fit_transform(df_copy)
        elif scaling_type == 'minmax':
            scaler = MinMaxScaler(variables=columns)
            df_copy = scaler.fit_transform(df_copy)
        
        # Apply transformation to session
        operation_description = f"Applied {scaling_type} scaling to {len(columns)} numeric columns"
        success = session_manager.apply_transformation(df_copy, operation_description)
        
        if not success:
            return JsonResponse({
                'success': False,
                'error': 'Failed to apply transformation'
            }, status=500)
        
        # Return updated data preview and session info
        session_info = session_manager.get_session_info()
        data_preview = df_copy.head(100).to_dict('records')
        
        return JsonResponse({
            'success': True,
            'message': operation_description,
            'session_info': session_info,
            'data_preview': data_preview,
            'transformation_applied': {
                'type': 'feature_scaling',
                'columns': columns,
                'scaling_type': scaling_type,
                'rows_affected': len(df_copy)
            }
        })
        
    except Exception as e:
        logger.error(f"Failed to apply feature scaling: {e}")
        return JsonResponse({
            'success': False,
            'error': str(e)
        }, status=500)


@csrf_exempt
@login_required
@require_http_methods(["POST"])
def apply_outlier_treatment(request, datasource_id):
    """
    Apply outlier treatment using Winsorization.
    """
    try:
        datasource = get_object_or_404(DataSource, id=datasource_id, project__owner=request.user)
        session_manager = get_session_manager(request.user.id, datasource_id)
        
        current_df = session_manager.get_current_dataframe()
        if current_df is None:
            return JsonResponse({
                'success': False,
                'error': 'No active session found. Please initialize session first.'
            }, status=400)
        
        # Parse request data
        data = json.loads(request.body)
        columns = data.get('columns', [])
        capping_method = data.get('capping_method', 'quantiles')  # quantiles, iqr
        tail = data.get('tail', 'both')  # both, right, left
        quantiles = data.get('quantiles', [0.05, 0.95])
        
        if not columns:
            return JsonResponse({
                'success': False,
                'error': 'No columns specified for outlier treatment'
            }, status=400)
        
        # Validate columns are numeric
        numeric_cols = current_df.select_dtypes(include=[np.number]).columns
        invalid_cols = [col for col in columns if col not in numeric_cols]
        
        if invalid_cols:
            return JsonResponse({
                'success': False,
                'error': f'Columns {invalid_cols} are not numeric'
            }, status=400)
        
        # Apply transformation
        df_copy = current_df.copy()
        
        winsorizer = Winsorizer(
            capping_method=capping_method,
            tail=tail,
            quantiles=quantiles,
            variables=columns
        )
        df_copy = winsorizer.fit_transform(df_copy)
        
        # Apply transformation to session
        operation_description = f"Applied outlier treatment to {len(columns)} columns using {capping_method} method"
        success = session_manager.apply_transformation(df_copy, operation_description)
        
        if not success:
            return JsonResponse({
                'success': False,
                'error': 'Failed to apply transformation'
            }, status=500)
        
        # Return updated data preview and session info
        session_info = session_manager.get_session_info()
        data_preview = df_copy.head(100).to_dict('records')
        
        return JsonResponse({
            'success': True,
            'message': operation_description,
            'session_info': session_info,
            'data_preview': data_preview,
            'transformation_applied': {
                'type': 'outlier_treatment',
                'columns': columns,
                'method': capping_method,
                'rows_affected': len(df_copy)
            }
        })
        
    except Exception as e:
        logger.error(f"Failed to apply outlier treatment: {e}")
        return JsonResponse({
            'success': False,
            'error': str(e)
        }, status=500)


@csrf_exempt
@login_required
@require_http_methods(["POST"])
def apply_feature_engineering(request, datasource_id):
    """
    Apply feature engineering transformations (new columns based on formulas).
    """
    try:
        datasource = get_object_or_404(DataSource, id=datasource_id, project__owner=request.user)
        session_manager = get_session_manager(request.user.id, datasource_id)
        
        current_df = session_manager.get_current_dataframe()
        if current_df is None:
            return JsonResponse({
                'success': False,
                'error': 'No active session found. Please initialize session first.'
            }, status=400)
        
        # Parse request data
        data = json.loads(request.body)
        new_column_name = data.get('new_column_name')
        formula_string = data.get('formula_string')
        
        if not new_column_name or not formula_string:
            return JsonResponse({
                'success': False,
                'error': 'Both new_column_name and formula_string are required'
            }, status=400)
        
        # Apply transformation
        df_copy = current_df.copy()
        
        try:
            # Evaluate the formula safely
            # This is a simplified implementation - in production you'd want more security
            df_copy[new_column_name] = df_copy.eval(formula_string)
        except Exception as formula_error:
            return JsonResponse({
                'success': False,
                'error': f'Formula evaluation failed: {str(formula_error)}'
            }, status=400)
        
        # Apply transformation to session
        operation_description = f"Created new column '{new_column_name}' using formula: {formula_string}"
        success = session_manager.apply_transformation(df_copy, operation_description)
        
        if not success:
            return JsonResponse({
                'success': False,
                'error': 'Failed to apply transformation'
            }, status=500)
        
        # Return updated data preview and session info
        session_info = session_manager.get_session_info()
        data_preview = df_copy.head(100).to_dict('records')
        
        return JsonResponse({
            'success': True,
            'message': operation_description,
            'session_info': session_info,
            'data_preview': data_preview,
            'transformation_applied': {
                'type': 'feature_engineering',
                'new_column': new_column_name,
                'formula': formula_string,
                'rows_affected': len(df_copy)
            }
        })
        
    except Exception as e:
        logger.error(f"Failed to apply feature engineering: {e}")
        return JsonResponse({
            'success': False,
            'error': str(e)
        }, status=500)


@csrf_exempt
@login_required
@require_http_methods(["POST"])
def apply_column_operations(request, datasource_id):
    """
    Apply column operations (drop, rename, reorder).
    """
    try:
        datasource = get_object_or_404(DataSource, id=datasource_id, project__owner=request.user)
        session_manager = get_session_manager(request.user.id, datasource_id)
        
        current_df = session_manager.get_current_dataframe()
        if current_df is None:
            return JsonResponse({
                'success': False,
                'error': 'No active session found. Please initialize session first.'
            }, status=400)
        
        # Parse request data
        data = json.loads(request.body)
        operation = data.get('operation')  # drop, rename, reorder
        
        # Apply transformation
        df_copy = current_df.copy()
        operation_description = ""
        
        if operation == 'drop':
            columns_to_drop = data.get('columns', [])
            if not columns_to_drop:
                return JsonResponse({
                    'success': False,
                    'error': 'No columns specified for dropping'
                }, status=400)
            
            df_copy = df_copy.drop(columns=columns_to_drop)
            operation_description = f"Dropped {len(columns_to_drop)} columns: {', '.join(columns_to_drop)}"
            
        elif operation == 'rename':
            column_mapping = data.get('column_mapping', {})
            if not column_mapping:
                return JsonResponse({
                    'success': False,
                    'error': 'No column mapping specified for renaming'
                }, status=400)
            
            df_copy = df_copy.rename(columns=column_mapping)
            operation_description = f"Renamed {len(column_mapping)} columns"
            
        elif operation == 'reorder':
            new_order = data.get('new_order', [])
            if not new_order or len(new_order) != len(df_copy.columns):
                return JsonResponse({
                    'success': False,
                    'error': 'Invalid column order specified'
                }, status=400)
            
            df_copy = df_copy[new_order]
            operation_description = "Reordered columns"
            
        else:
            return JsonResponse({
                'success': False,
                'error': f'Unknown column operation: {operation}'
            }, status=400)
        
        # Apply transformation to session
        success = session_manager.apply_transformation(df_copy, operation_description)
        
        if not success:
            return JsonResponse({
                'success': False,
                'error': 'Failed to apply transformation'
            }, status=500)
        
        # Return updated data preview and session info
        session_info = session_manager.get_session_info()
        data_preview = df_copy.head(100).to_dict('records')
        column_info = [
            {
                'field': col,
                'headerName': col,
                'type': str(df_copy[col].dtype),
                'filter': True,
                'sortable': True,
                'resizable': True
            }
            for col in df_copy.columns
        ]
        
        return JsonResponse({
            'success': True,
            'message': operation_description,
            'session_info': session_info,
            'data_preview': data_preview,
            'column_info': column_info,
            'transformation_applied': {
                'type': 'column_operations',
                'operation': operation,
                'rows_affected': len(df_copy),
                'columns_count': len(df_copy.columns)
            }
        })
        
    except Exception as e:
        logger.error(f"Failed to apply column operations: {e}")
        return JsonResponse({
            'success': False,
            'error': str(e)
        }, status=500)
